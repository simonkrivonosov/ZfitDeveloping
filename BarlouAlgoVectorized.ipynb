{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: zfit is being actively developed and keeps up with the newest versions of other packages.\n",
      "This includes Python itself. Therefore, Python 3.6 will be dropped in the near future (beginning of May 2021)\n",
      "and 3.9 will be added to the supported versions.\n",
      "\n",
      "Feel free to contact us in case of problems to upgrade to a more recent version of Python.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/zfit/__init__.py:48: UserWarning: TensorFlow warnings are by default suppressed by zfit. In order to show them, set the environment variable ZFIT_DISABLE_TF_WARNINGS=0. In order to suppress the TensorFlow warnings AND this warning, set ZFIT_DISABLE_TF_WARNINGS=1.\n",
      "  warnings.warn(\"TensorFlow warnings are by default suppressed by zfit.\"\n",
      "/anaconda3/lib/python3.6/site-packages/zfit/util/execution.py:73: UserWarning: Not running on Linux. Determining available cpus for thread can failand be overestimated. Workaround (only if too many cpus are used):`zfit.run.set_n_cpu(your_cpu_number)`\n",
      "  warnings.warn(\"Not running on Linux. Determining available cpus for thread can fail\"\n"
     ]
    }
   ],
   "source": [
    "import zfit\n",
    "import math\n",
    "from zfit import z\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "zfit.settings.options['numerical_grad'] = True\n",
    "class HistPDF(zfit.pdf.BasePDF):\n",
    "\n",
    "    def __init__(self, hist_args, hist_bins, obs, name='HistPDF'):\n",
    "        self.rv_hist = scipy.stats.rv_histogram([hist_args, hist_bins])\n",
    "        super().__init__(obs=obs, name=name)\n",
    "\n",
    "    def _unnormalized_pdf(self, x):\n",
    "        x = z.unstack_x(x)\n",
    "        probs =  z.py_function(func=self.rv_hist.pdf, inp=[x], Tout=tf.float64)\n",
    "        probs.set_shape(x.shape)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu2 = zfit.Parameter(\"mu2\", 5., step_size=0)\n",
    "# sigma2 = zfit.Parameter(\"sigma2\", 1., step_size=0)\n",
    "# lambd2 = zfit.Parameter(\"lambda2\", -0.2, step_size=0)\n",
    "# frac2 = zfit.Parameter(\"fraction2\", 0.5, 0, 1)\n",
    "# frac1 = zfit.Parameter(\"fraction1\", 0.5, step_size=0)\n",
    "# create space\n",
    "obs1 = zfit.Space(\"x\", limits=(0, 10))\n",
    "obs2 = zfit.Space(\"x\", limits=(0, 10))\n",
    "\n",
    "# parameters\n",
    "mu1 = zfit.Parameter(\"mu1\", 5., 1, 10, step_size=0)\n",
    "sigma1 = zfit.Parameter(\"sigma1\", 1., 0.1, 10, step_size=0)\n",
    "lambd1 = zfit.Parameter(\"lambda1\", -0.2, -1, -0.01, step_size=0)\n",
    "frac1 = zfit.Parameter(\"fraction1\", 0.5, 0, 1)\n",
    "\n",
    "mu2 = zfit.Parameter(\"mu2\", 5., step_size=0)\n",
    "sigma2 = zfit.Parameter(\"sigma2\", 1., step_size=0)\n",
    "lambd2 = zfit.Parameter(\"lambda2\", -0.2, step_size=0)\n",
    "frac2 = zfit.Parameter(\"fraction2\", 0.5, step_size=0)\n",
    "\n",
    "\n",
    "gauss1 = zfit.pdf.Gauss(mu=mu1, sigma=sigma1, obs=obs1)\n",
    "exponential1 = zfit.pdf.Exponential(lambd1, obs=obs1)\n",
    "model1 = zfit.pdf.SumPDF([gauss1, exponential1], fracs=frac1)\n",
    "\n",
    "\n",
    "gauss2 = zfit.pdf.Gauss(mu=mu2, sigma=sigma2, obs=obs2)\n",
    "exponential2 = zfit.pdf.Exponential(lambd2, obs=obs2)\n",
    "model2 = zfit.pdf.SumPDF([gauss2, exponential2], fracs=frac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 1000000\n",
    "\n",
    "exp_data = exponential2.sample(n=n_sample * (1 - frac1)).numpy()\n",
    "\n",
    "gauss_data = gauss2.sample(n=n_sample * frac1).numpy()\n",
    "\n",
    "data = model1.create_sampler(n_sample, limits=obs1)\n",
    "data.resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = data[:, 0].numpy()\n",
    "exp_data_np = exp_data[:, 0]\n",
    "gauss_data_np = gauss_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3894b6f52a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexp_data_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_data_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgauss_data_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgauss_data_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msim_hists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msim_hists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_data_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "data_hist = np.histogram(data_np, bins=1000)\n",
    "exp_data_hist = np.histogram(exp_data_np, bins=1000)\n",
    "gauss_data_hist = np.histogram(gauss_data_np, bins=1000)\n",
    "sim_hists = []\n",
    "sim_hists.append(exp_data_hist)\n",
    "sim_hists.append(gauss_data_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorflow.experimental.numpy as tnp  # TODO 1: replace (possible) np calls with tnp\n",
    "class FractionFitterV3:\n",
    "\n",
    "    def __init__(self, data_hist, sim_hists, P):\n",
    "        self.data_hist = data_hist\n",
    "        self.P = np.array(P)  # vectorization 3\n",
    "        self.sim_hists = [hist for hist in sim_hists]\n",
    "        self.d = np.array(self.data_hist[0]) # where d[i] amount of events in bin from data\n",
    "        self.N_D = np.sum(self.d)#all observable data amount\n",
    "\n",
    "        # vectorization 3\n",
    "        self.N = np.array([np.sum(h[0]) for h in sim_hists])# amount of simulation data from sources e.g. N[0] from source 0 .. N[j] from source j\n",
    "        self.sources_num = len(P)\n",
    "        self.bins_num = len(data_hist[0])\n",
    "        self.p = self.N_D * self.P / self.N\n",
    "        self.a = np.array([self.sim_hists[j][0] for j in range(self.sources_num)])\n",
    "        self.nonzero_indices = np.where(self.d != 0)[0]\n",
    "        zfit.run.set_autograd_mode(False)\n",
    "        zfit.run.set_graph_mode(False)\n",
    "        \n",
    "    def norma(self, v):\n",
    "        return math.sqrt(np.sum(v ** 2))\n",
    "    #function to minimize for finding optimat t according to (15) from the paper        \n",
    "    def f(self, t, a, p, i):\n",
    "        return np.sum((p * a[:, i] / (1 + p * t))) - self.d[i]/(1 - t)\n",
    "    \n",
    "    def f_vectorized(self, t, a, p, i):  # add an axis argumend to sum\n",
    "        term1 = np.sum((p[:, None] * a[:, i] / (1 + p[:, None] * t[None, :])),\n",
    "                       axis=0)\n",
    "        term2 = self.d[i]/(1 - t)\n",
    "        return term1 - term2\n",
    "    \n",
    "    def jac_f(self, t, a, p, i):\n",
    "        return np.diag(np.sum((p[:, None] * a[:, i] * p[:, None])/(1 + p[:, None] * t[None, :])**2, axis=0) + self.d[i]/(1 - t)**2)\n",
    "    \n",
    "    def sqF(self, p):\n",
    "        t = np.ones_like(self.d)\n",
    "        x0 = t[self.nonzero_indices] * 0 #may be 0.01?\n",
    "        p = np.asarray(p)\n",
    "        # TODO 3: replace with https://www.tensorflow.org/probability/api_docs/python/tfp/math/find_root_chandrupatla\n",
    "        t_solved = scipy.optimize.root(self.f_vectorized,\n",
    "                                       x0=x0, \n",
    "                                    #    x0=0.1 * np.ones_like(nonzero_indices), \n",
    "                                       args=(self.a, p, self.nonzero_indices),\n",
    "                                       jac=self.jac_f,\n",
    "                                       method='hybr',  # 'krylov',\n",
    "                                       tol=None,\n",
    "                                       callback=None,\n",
    "                                       options={}).x # bounds(-1/max(p), 1)\n",
    "        t[self.nonzero_indices] = t_solved\n",
    "        #A[j][i] fitted amount of observations in i bin from j source\n",
    "        A = self.a/(1 + p[:, None]*t[None, :])\n",
    "        A = np.maximum(A, 0.05)\n",
    "        \n",
    "        return np.sum(np.sum((self.d[None, :] * A)/np.sum(p[None, :] * A.transpose(), axis=1) - A, axis=1)**2, axis=0)\n",
    "    sqF.errordef = 0.5\n",
    "    \n",
    "    def fit(self, eps):\n",
    "        minimizer = zfit.minimize.Minuit(tol=eps)  # 2: \n",
    "        p_new = np.array(minimizer.minimize(self.sqF, self.p).params)   \n",
    "        print(np.abs(self.norma(p_new) - self.norma(self.p)))\n",
    "        return p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = FractionFitterV3(data_hist=data_hist, sim_hists=sim_hists, P=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02656691298060676\n"
     ]
    }
   ],
   "source": [
    "p = fitter.fit(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "15.6 s ± 147 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit for _ in range(2): True\n",
    "p = fitter.fit(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "for j in range(len(p)):\n",
    "    P.append(p[j] * fitter.N[j]/fitter.N_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25059.392597172402, 6305.526908127644]"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant([[1, 2], [3, 4]])                 \n",
    "b = tf.add(a, 1)\n",
    "\n",
    "\"\"\"This example illustrates how to minimize an arbitrary Python function using the zfit minimizer.\n",
    "17.4 s ± 514 ms per loop\n",
    "This may has some overhead in the beginning and won't be instantly fast compared to other libraries if run once.\n",
    "\n",
    "Copyright (c) 2021 zfit\n",
    "\"\"\"\n",
    "\n",
    "#  Copyright (c) 2021 zfit\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import zfit\n",
    "\n",
    "# set everything to numpy mode\n",
    "zfit.run.set_autograd_mode(False)\n",
    "zfit.run.set_graph_mode(False)\n",
    "\n",
    "# create our favorite minimizer\n",
    "# minimizer = zfit.minimize.IpyoptV1()\n",
    "\n",
    "\n",
    "# minimizer = zfit.minimize.Minuit()\n",
    "# minimizer = zfit.minimize.ScipyTrustKrylovV1()\n",
    "minimizer = zfit.minimize.NLoptLBFGSV1()\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    x = np.array(x)  # make sure it's an array\n",
    "    return np.sum((x - 0.1) ** 2 + x[1] ** 4)\n",
    "\n",
    "\n",
    "# we can also use a more complicated function instead\n",
    "# from scipy.optimize import rosen as func\n",
    "\n",
    "\n",
    "# we need to set the errordef, the definition of \"1 sigma\"\n",
    "func.errordef = 0.5\n",
    "\n",
    "# initial parameters\n",
    "params = [1, -3, 2, 1.4, 11]\n",
    "# or for a more fine-grained control\n",
    "# params = {\n",
    "#     'value': [1, -3, 2, 1.4, 11],  # mandatory\n",
    "#     'lower': [-2, -5, -5, -10, -15],  # lower bound, can be omitted\n",
    "#     'upper': [2, 4, 5, 10, 15],  # upper bound, can be omitted\n",
    "#     'step_size': [0.1] * 5,  # initial step size, can be omitted\n",
    "# }\n",
    "\n",
    "# minimize\n",
    "result = minimizer.minimize(func, params)\n",
    "\n",
    "# estimate errors\n",
    "result.hesse()\n",
    "result.errors()\n",
    "print(np.arraresult.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.resample()\n",
    "data_np = data[:, 0].numpy()\n",
    "data_hist = np.histogram(data_np, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5]])\n",
    "p = np.array([1,2,3,4,5,6,7])\n",
    "d = np.array([1,2,3,4,5])\n",
    "t = np.array([1,2,3,4,5])\n",
    "\n",
    "A = a/(1 + p[:, None]*t[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.sum((d * A)/np.sum(p * A.transpose(), axis=1) - A, axis=1)**2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "bins = [math.log2(10), math.log2(100), math.log2(500), math.log2(1000)]\n",
    "times = [60.5, 123, 7000, 53700]\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.xlabel('log(bins_num) - количество бинов')\n",
    "plt.ylabel('T - время работы программы, ms')\n",
    "plt.scatter(bins, times)\n",
    "plt.plot(bins, times, 'r', label='T(bins_num)')\n",
    "plt.legend(bbox_to_anchor=(0.6, 1), loc=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zfit \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.stats\n",
    "from zfit import z\n",
    "import random\n",
    "obs = zfit.Space(\"x\", limits=(0, 10))\n",
    "\n",
    "mu = zfit.Parameter(\"mu\", 5., step_size=0)\n",
    "sigma = zfit.Parameter(\"sigma\", 1., step_size=0)\n",
    "lambd = zfit.Parameter(\"lambda\", -0.2, step_size=0)\n",
    "frac = zfit.Parameter(\"fraction\", 0.5, step_size=0)\n",
    "\n",
    "mu1 = zfit.Parameter(\"mu2\", 5., 0, 10)\n",
    "sigma1 = zfit.Parameter(\"sigma2\", 1., 0.1, 2)\n",
    "lambd1 = zfit.Parameter(\"lambda2\", -0.2, -0.5, 0.5)\n",
    "frac1 = zfit.Parameter(\"fraction2\", 0.5, 0, 1)\n",
    "\n",
    "gauss = zfit.pdf.Gauss(mu=mu, sigma=sigma, obs=obs)\n",
    "exponential = zfit.pdf.Exponential(lambd, obs=obs)\n",
    "model = zfit.pdf.SumPDF([gauss, exponential], fracs=frac)\n",
    "\n",
    "gauss1 = zfit.pdf.Gauss(mu=mu1, sigma=sigma1, obs=obs)\n",
    "exponential1 = zfit.pdf.Exponential(lambd1, obs=obs)\n",
    "model1 = zfit.pdf.SumPDF([gauss1, exponential1], fracs=frac1)\n",
    "# data\n",
    "n_sample = 100\n",
    "\n",
    "exp_data = exponential.sample(n=n_sample * (1 - frac)).numpy()\n",
    "gauss_data = gauss.sample(n=n_sample * frac).numpy()\n",
    "data = model.create_sampler(n_sample, limits=obs)\n",
    "\n",
    "data.resample()\n",
    "n_sim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfit.run.set_graph_mode(False)\n",
    "zfit.settings.options['numerical_grad'] = True\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "c = 0\n",
    "arr = np.empty((3, 3), dtype=\"float32\")\n",
    "arn_sim = [100, 500, 1000]\n",
    "\n",
    "for i in range(0, 3):\n",
    "    n_sim = arn_sim[i]\n",
    "    print(n_sim)\n",
    "    gauss_hist = gauss.create_sampler(n_sim, limits=obs)\n",
    "    exp_hist = exponential.create_sampler(n_sim, limits=obs)\n",
    "    print(exp_hist)\n",
    "    minimizer = zfit.minimize.Minuit()\n",
    "    mean_bias = []\n",
    "    minimizer = zfit.minimize.Minuit(verbosity = 0)\n",
    "    for m in range(0, 30):\n",
    "        print(\"Прогон номер \", m)\n",
    "        res = []\n",
    "        models = []\n",
    "        gauss_hist.resample()\n",
    "        data_np = gauss_hist[:, 0].numpy()\n",
    "        histogramm = np.histogram(data_np, bins=100)\n",
    "        gauss_hist_init = HistPDF(histogramm[0], histogramm[1], obs = obs)\n",
    "#         exp_hist.resample()\n",
    "#         exp_data_np = exp_hist[:, 0].numpy()\n",
    "#         exp_histogramm = np.histogram(exp_data_np, bins=100)\n",
    "#         exp_hist_init = HistPDF(exp_histogramm[0], exp_histogramm[1], obs = obs)\n",
    "        modelHist = zfit.pdf.SumPDF([gauss_hist_init, exponential1], fracs=frac1)\n",
    "        nll2 = zfit.loss.UnbinnedNLL(model=modelHist, data=data) \n",
    "        for i in range(0, 30):\n",
    "            data.resample()\n",
    "            result1 = minimizer.minimize(nll2, params=[frac1])  \n",
    "            value_stat = list(result1.error().keys())[0] \n",
    "            error_stat = list(result1.error().values())[0] \n",
    "            del result1\n",
    "            frac_value = float(value_stat.value())  \n",
    "            res.append(final_value) \n",
    "        (mu_ar, sigma_ar) = norm.fit(res)\n",
    "        mean_bias.append(mu_ar)\n",
    "    (mu_si, sigma_si) = norm.fit(mean_bias)\n",
    "    arr[c, 0] = n_sim\n",
    "    arr[c, 1] = mu_si\n",
    "    arr[c, 2] = sigma_si\n",
    "    c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zfit.run.set_graph_mode(False)\n",
    "zfit.settings.options['numerical_grad'] = True\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "c = 0\n",
    "arr = np.empty((7, 3), dtype=\"float32\")\n",
    "arn_sim = [10, 25, 50, 100, 500, 1000, 3000]\n",
    "\n",
    "for i in range(0, 7):\n",
    "    n_sim = arn_sim[i]\n",
    "    print(n_sim)\n",
    "    data_hist = gauss.create_sampler(n_sim, limits=obs)\n",
    "    # data1 = hist_init.create_sampler(n_sample, limits=obs)\n",
    "    # data1.resample()\n",
    "    # data_sim = gauss.create_sampler(n_sim, limits=obs)\n",
    "    minimizer = zfit.minimize.Minuit()\n",
    "    mean_bias = []\n",
    "    minimizer = zfit.minimize.Minuit(verbosity = 0)\n",
    "    # nll1 = zfit.loss.UnbinnedNLL(model=hist_init, data=data_sim)\n",
    "    for m in range(0, 30):\n",
    "        print(\"Прогон номер \", m)\n",
    "        res = []\n",
    "        models = []\n",
    "        data_hist.resample()\n",
    "        data_np = data_hist[:, 0].numpy()\n",
    "        histogramm = np.histogram(data_np, bins=100)\n",
    "        hist_init = HistPDF(histogramm[0], histogramm[1], obs = obs)\n",
    "        modelHist = zfit.pdf.SumPDF([hist_init, exponential1], fracs=frac1)\n",
    "        nll2 = zfit.loss.UnbinnedNLL(model=modelHist, data=data) \n",
    "        for i in range(0, 30):\n",
    "            data.resample()\n",
    "            result1 = minimizer.minimize(nll2, params=[frac1])  \n",
    "            value_stat = list(result1.error().keys())[0] \n",
    "            error_stat = list(result1.error().values())[0] \n",
    "            del result1\n",
    "            frac_value = float(value_stat.value()) \n",
    "            frac_up_error = float(error_stat['upper']) \n",
    "            frac_low_error = float(error_stat['lower']) \n",
    "            if(frac_value - 0.5 > 0): \n",
    "                frac_error = frac_up_error \n",
    "            else: \n",
    "                frac_error = abs(frac_low_error) \n",
    "            final_value = (0.5-frac_value)/(frac_error) \n",
    "            res.append(final_value)\n",
    "         \n",
    "        (mu_ar, sigma_ar) = norm.fit(res)\n",
    "        mean_bias.append(mu_ar)\n",
    "    (mu_si, sigma_si) = norm.fit(mean_bias)\n",
    "\n",
    "    arr[c, 0] = n_sim\n",
    "    arr[c, 1] = mu_si\n",
    "    arr[c, 2] = sigma_si\n",
    "    c = c + 1\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92 s ± 7.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit for _ in range(2): True\n",
    "np.sum(np.ones((100,100,100,100, 2)) * np.ones((100,100,100,100, 2)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-709-6f613f3da4fa>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-709-6f613f3da4fa>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pip install jaxlib\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%timeit for _ in range(2): True\n",
    "tnp.sum(tnp.array(np.ones((100,100,100,100, 2))) * tnp.array(np.ones((100,100,100,100, 2))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tnp version!!!\n",
    "import scipy\n",
    "import tensorflow.experimental.numpy as tnp  # TODO 1: replace (possible) np calls with tnp\n",
    "from tensorflow_probability.python.math.root_search import find_root_chandrupatla\n",
    "class FractionFitterV3:\n",
    "\n",
    "    def __init__(self, data_hist, sim_hists, P):\n",
    "        self.data_hist = data_hist\n",
    "        self.P = np.array(P)  # vectorization 3\n",
    "        self.sim_hists = [hist for hist in sim_hists]\n",
    "        self.d = np.array(self.data_hist[0]) # where d[i] amount of events in bin from data\n",
    "        self.N_D = np.sum(self.d)#all observable data amount\n",
    "\n",
    "        # vectorization 3\n",
    "        self.N = np.array([np.sum(h[0]) for h in sim_hists])# amount of simulation data from sources e.g. N[0] from source 0 .. N[j] from source j\n",
    "        self.sources_num = len(P)\n",
    "        self.bins_num = len(data_hist[0])\n",
    "        self.p = self.N_D * self.P / self.N\n",
    "        #a[j][i] amount of observations in i bin from j source\n",
    "        self.a = tf.constant([self.sim_hists[j][0] for j in range(self.sources_num)], dtype=\"int32\")\n",
    "        #self.a = tnp.array([self.sim_hists[j][0] for j in range(self.sources_num)], dtype=\"int64\")\n",
    "        self.nonzero_indices = np.where(self.d != 0)[0]\n",
    "        self.nonzero_indices_tf = np.array([[i] for i in self.nonzero_indices])\n",
    "        zfit.run.set_autograd_mode(False)\n",
    "        zfit.run.set_graph_mode(False)\n",
    "        \n",
    "    def norma(self, v):\n",
    "        return math.sqrt(sum(v ** 2))\n",
    "    #function to minimize for finding optimat t according to (15) from the paper        \n",
    "    \n",
    "    def f_vectorized(self, t, p):  # add an axis argumend to sum\n",
    "        term1 = tnp.sum(p[:, None]* tf.gather(self.a, self.nonzero_indices, axis=1) / (1 + p[:, None] * t[None, :]), axis=0)\n",
    "        term2 = self.d[self.nonzero_indices]/(1 - t)\n",
    "        return term1 - term2\n",
    "    \n",
    "    def jac_f(self, t, p):\n",
    "            return tnp.diag(tnp.sum((p[:, None] * tf.gather(self.a, self.nonzero_indices, axis=1) * p[:, None])/(1 + p[:, None] * t[None, :])**2, axis=0) + self.d[self.nonzero_indices]/(1 - t)**2)\n",
    "    \n",
    "    def sqF(self, p):\n",
    "        t = tnp.ones_like(self.d, dtype=\"int32\")\n",
    "        x0 = t[self.nonzero_indices] * 0 \n",
    "        p = tnp.array(np.asarray(p))\n",
    "        # TODO 3: replace with https://www.tensorflow.org/probability/api_docs/python/tfp/math/find_root_chandrupatla\n",
    "        def func_to_minimize(t):\n",
    "            return self.f_vectorized(t, p)\n",
    "        t_solved = scipy.optimize.root(self.f_vectorized,\n",
    "                                       x0=x0, \n",
    "                                    #    x0=0.1 * np.ones_like(nonzero_indices), \n",
    "                                       args=(p),\n",
    "                                       jac=self.jac_f,\n",
    "                                       method='hybr',  # 'krylov',\n",
    "                                       tol=None,\n",
    "                                       callback=None,\n",
    "                                       options={}).x # bounds(-1/max(p), 1)\n",
    "        t = tf.tensor_scatter_nd_update(t, self.nonzero_indices_tf, t_solved)\n",
    "#         A = tf.constant(self.a/(1 + p[:, None]*t[None, :]), dtype=\"float64\") \n",
    "        A = tnp.maximum(self.a/(1 + p[:, None]*t[None, :]), 0.05)\n",
    "        \n",
    "        return tnp.sum(tnp.sum(self.d[None, :] *  A / tnp.sum(p[None, :] * A.transpose(), axis=1) - A, axis=1)**2, axis=0)\n",
    "    sqF.errordef = 0.5\n",
    "    \n",
    "    def fit(self, eps):\n",
    "        minimizer = zfit.minimize.Minuit(tol=eps)  # 2: \n",
    "        p_new = np.array(minimizer.minimize(self.sqF, self.p).params)   \n",
    "        print(np.abs(self.norma(p_new) - self.norma(self.p)))\n",
    "        return p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = FractionFitterV3(data_hist=data_hist, sim_hists=sim_hists, P=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02656691298060676\n"
     ]
    }
   ],
   "source": [
    "# %%timeit for _ in range(2): True\n",
    "p = fitter.fit(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tnp version!!!\n",
    "import scipy\n",
    "import tensorflow.experimental.numpy as tnp \n",
    "from tensorflow_probability.python.math.root_search import find_root_chandrupatla\n",
    "class FractionFitterV4:\n",
    "\n",
    "    def __init__(self, data_hist, sim_hists, P):\n",
    "        self.data_hist = data_hist\n",
    "        self.P = np.array(P)  # vectorization 3\n",
    "        self.sim_hists = [hist for hist in sim_hists]\n",
    "        self.d = np.array(self.data_hist[0]) # where d[i] amount of events in bin from data\n",
    "        self.N_D = np.sum(self.d)#all observable data amount\n",
    "\n",
    "        # vectorization 3\n",
    "        self.N = np.array([np.sum(h[0]) for h in sim_hists])# amount of simulation data from sources e.g. N[0] from source 0 .. N[j] from source j\n",
    "        self.sources_num = len(P)\n",
    "        self.bins_num = len(data_hist[0])\n",
    "        self.p = self.N_D * self.P / self.N\n",
    "        #a[j][i] amount of observations in i bin from j source\n",
    "        self.a = tf.constant([self.sim_hists[j][0] for j in range(self.sources_num)], dtype=\"float64\")\n",
    "        #self.a = tnp.array([self.sim_hists[j][0] for j in range(self.sources_num)], dtype=\"int64\")\n",
    "        self.nonzero_indices = np.where(self.d != 0)[0]\n",
    "        self.nonzero_indices_tf = np.array([[i] for i in self.nonzero_indices])\n",
    "        zfit.run.set_autograd_mode(False)\n",
    "        zfit.run.set_graph_mode(False)\n",
    "        \n",
    "    def norma(self, v):\n",
    "        return math.sqrt(sum(v ** 2))\n",
    "    #function to minimize for finding optimal t according to (15) from the paper        \n",
    "    \n",
    "    def f_vectorized(self, t, p):  # add an axis argumend to sum\n",
    "        term1 = tnp.sum(p[:, None]* tf.gather(self.a, self.nonzero_indices, axis=1) / (1 + p[:, None] * t[None, :]), axis=0)\n",
    "        term2 = self.d[self.nonzero_indices]/(1 - t)\n",
    "        return term1 - term2\n",
    "    \n",
    "    def jac_f(self, t, p):\n",
    "            return tnp.diag(tnp.sum((p[:, None] * tf.gather(self.a, self.nonzero_indices, axis=1) * p[:, None])/(1 + p[:, None] * t[None, :])**2, axis=0) + self.d[self.nonzero_indices]/(1 - t)**2)\n",
    "    \n",
    "    def sqF(self, p):\n",
    "        t = tnp.ones_like(self.d, dtype=\"float64\")\n",
    "        x0 = t[self.nonzero_indices] * 0 \n",
    "        p = tnp.array(np.asarray(p))\n",
    "        high_bound = tnp.ones_like(t)\n",
    "        low_bound = high_bound * (-1/tnp.max(p))\n",
    "        # TODO 3: replace with https://www.tensorflow.org/probability/api_docs/python/tfp/math/find_root_chandrupatla\n",
    "        def func_to_minimize(t):\n",
    "            return self.f_vectorized(t, p)\n",
    "        t_solved = find_root_chandrupatla(func_to_minimize, low_bound, high_bound).estimated_root\n",
    "        t = tf.tensor_scatter_nd_update(t, self.nonzero_indices_tf, t_solved)\n",
    "#         A = tf.constant(self.a/(1 + p[:, None]*t[None, :]), dtype=\"float64\") \n",
    "        A = tnp.maximum(self.a/(1 + p[:, None]*t[None, :]), 0.05)\n",
    "        \n",
    "        return tnp.sum(tnp.sum(self.d[None, :] *  A / tnp.sum(p[None, :] * A.transpose(), axis=1) - A, axis=1)**2, axis=0)\n",
    "    sqF.errordef = 0.5\n",
    "    \n",
    "    def fit(self, eps):\n",
    "        minimizer = zfit.minimize.Minuit(tol=eps)  # 2: \n",
    "        p_new = np.array(minimizer.minimize(self.sqF, self.p).params)   \n",
    "        print(np.abs(self.norma(p_new) - self.norma(self.p)))\n",
    "        return p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02652955209427721\n"
     ]
    }
   ],
   "source": [
    "fitter = FractionFitterV4(data_hist=data_hist, sim_hists=sim_hists, P=[0.4, 0.6])\n",
    "p = fitter.fit(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
