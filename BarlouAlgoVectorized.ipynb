{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: zfit is being actively developed and keeps up with the newest versions of other packages.\n",
      "This includes Python itself. Therefore, Python 3.6 will be dropped in the near future (beginning of May 2021)\n",
      "and 3.9 will be added to the supported versions.\n",
      "\n",
      "Feel free to contact us in case of problems to upgrade to a more recent version of Python.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/zfit/__init__.py:48: UserWarning: TensorFlow warnings are by default suppressed by zfit. In order to show them, set the environment variable ZFIT_DISABLE_TF_WARNINGS=0. In order to suppress the TensorFlow warnings AND this warning, set ZFIT_DISABLE_TF_WARNINGS=1.\n",
      "  warnings.warn(\"TensorFlow warnings are by default suppressed by zfit.\"\n",
      "/anaconda3/lib/python3.6/site-packages/zfit/util/execution.py:73: UserWarning: Not running on Linux. Determining available cpus for thread can failand be overestimated. Workaround (only if too many cpus are used):`zfit.run.set_n_cpu(your_cpu_number)`\n",
      "  warnings.warn(\"Not running on Linux. Determining available cpus for thread can fail\"\n"
     ]
    }
   ],
   "source": [
    "import zfit\n",
    "import math\n",
    "from zfit import z\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "zfit.settings.options['numerical_grad'] = True\n",
    "class HistPDF(zfit.pdf.BasePDF):\n",
    "\n",
    "    def __init__(self, hist_args, hist_bins, obs, name='HistPDF'):\n",
    "        self.rv_hist = scipy.stats.rv_histogram([hist_args, hist_bins])\n",
    "        super().__init__(obs=obs, name=name)\n",
    "\n",
    "    def _unnormalized_pdf(self, x):\n",
    "        x = z.unstack_x(x)\n",
    "        probs =  z.py_function(func=self.rv_hist.pdf, inp=[x], Tout=tf.float64)\n",
    "        probs.set_shape(x.shape)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu2 = zfit.Parameter(\"mu2\", 5., step_size=0)\n",
    "# sigma2 = zfit.Parameter(\"sigma2\", 1., step_size=0)\n",
    "# lambd2 = zfit.Parameter(\"lambda2\", -0.2, step_size=0)\n",
    "# frac2 = zfit.Parameter(\"fraction2\", 0.5, 0, 1)\n",
    "# frac1 = zfit.Parameter(\"fraction1\", 0.5, step_size=0)\n",
    "# create space\n",
    "obs1 = zfit.Space(\"x\", limits=(0, 10))\n",
    "obs2 = zfit.Space(\"x\", limits=(0, 10))\n",
    "\n",
    "# parameters\n",
    "mu1 = zfit.Parameter(\"mu1\", 5., 1, 10, step_size=0)\n",
    "sigma1 = zfit.Parameter(\"sigma1\", 1., 0.1, 10, step_size=0)\n",
    "lambd1 = zfit.Parameter(\"lambda1\", -0.2, -1, -0.01, step_size=0)\n",
    "frac1 = zfit.Parameter(\"fraction1\", 0.5, 0, 1)\n",
    "\n",
    "mu2 = zfit.Parameter(\"mu2\", 5., step_size=0)\n",
    "sigma2 = zfit.Parameter(\"sigma2\", 1., step_size=0)\n",
    "lambd2 = zfit.Parameter(\"lambda2\", -0.2, step_size=0)\n",
    "frac2 = zfit.Parameter(\"fraction2\", 0.5, step_size=0)\n",
    "\n",
    "\n",
    "gauss1 = zfit.pdf.Gauss(mu=mu1, sigma=sigma1, obs=obs1)\n",
    "exponential1 = zfit.pdf.Exponential(lambd1, obs=obs1)\n",
    "model1 = zfit.pdf.SumPDF([gauss1, exponential1], fracs=frac1)\n",
    "\n",
    "\n",
    "gauss2 = zfit.pdf.Gauss(mu=mu2, sigma=sigma2, obs=obs2)\n",
    "exponential2 = zfit.pdf.Exponential(lambd2, obs=obs2)\n",
    "model2 = zfit.pdf.SumPDF([gauss2, exponential2], fracs=frac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 1000000\n",
    "\n",
    "exp_data = exponential2.sample(n=n_sample * (1 - frac1)).numpy()\n",
    "\n",
    "gauss_data = gauss2.sample(n=n_sample * frac1).numpy()\n",
    "\n",
    "data = model1.create_sampler(n_sample, limits=obs1)\n",
    "data.resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = data[:, 0].numpy()\n",
    "exp_data_np = exp_data[:, 0]\n",
    "gauss_data_np = gauss_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hist = np.histogram(data_np, bins=1000)\n",
    "exp_data_hist = np.histogram(exp_data_np, bins=1000)\n",
    "gauss_data_hist = np.histogram(gauss_data_np, bins=1000)\n",
    "sim_hists = []\n",
    "sim_hists.append(exp_data_hist)\n",
    "sim_hists.append(gauss_data_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = FractionFitterV1(data_hist=data_hist, sim_hists=sim_hists, P=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02656691298060676\n"
     ]
    }
   ],
   "source": [
    "p = fitter.fit(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "0.02656442626066613\n",
      "15.6 s ± 147 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit for _ in range(2): True\n",
    "p = fitter.fit(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "for j in range(len(p)):\n",
    "    P.append(p[j] * fitter.N[j]/fitter.N_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25059.392597172402, 6305.526908127644]"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tnp version!!!\n",
    "import scipy\n",
    "import tensorflow.experimental.numpy as tnp \n",
    "import tensorflow_probability as tfp  # \n",
    "\n",
    "class FractionFitterV2:\n",
    "\n",
    "    def __init__(self, data_hist, sim_hists, P):\n",
    "        self.data_hist = data_hist\n",
    "        self.P = np.array(P)  # vectorization 3\n",
    "        self.sim_hists = [hist for hist in sim_hists]\n",
    "        self.d = np.array(self.data_hist[0]) # where d[i] amount of events in bin from data\n",
    "        self.N_D = np.sum(self.d)#all observable data amount\n",
    "\n",
    "        self.N = np.array([np.sum(h[0]) for h in sim_hists])# amount of simulation data from sources e.g. N[0] from source 0 .. N[j] from source j\n",
    "        self.sources_num = len(P)\n",
    "        self.bins_num = len(data_hist[0])\n",
    "        print(self.N_D)\n",
    "        print(self.P)\n",
    "        self.p = self.N_D * self.P / self.N\n",
    "        #a[j][i] amount of observations in i bin from j source\n",
    "        self.a = tf.constant([self.sim_hists[j][0] for j in range(self.sources_num)], dtype=\"float64\")\n",
    "        #self.a = tnp.array([self.sim_hists[j][0] for j in range(self.sources_num)], dtype=\"int64\")\n",
    "        self.nonzero_indices = np.where(self.d != 0)[0]\n",
    "        self.nonzero_indices_tf = np.array([[i] for i in self.nonzero_indices])\n",
    "        zfit.run.set_autograd_mode(False)\n",
    "        #zfit.run.set_graph_mode(False)\n",
    "        \n",
    "    \n",
    "    def norma(self, v):\n",
    "        return math.sqrt(sum(v ** 2))\n",
    "    #function to minimize for finding optimal t according to (15) from the paper        \n",
    "    \n",
    "    @tf.function(autograph=False)\n",
    "    def f_vectorized(self, t, p): \n",
    "        term1 = tnp.sum(p[:, None]* tf.gather(self.a, self.nonzero_indices, axis=1) / (1 + p[:, None] * t[None, :]), axis=0)\n",
    "        term2 = self.d[self.nonzero_indices]/(1 - t)\n",
    "        return term1 - term2\n",
    "    \n",
    "    @tf.function(autograph=False)\n",
    "    def jac_f(self, t, p):\n",
    "            return tnp.diag(tnp.sum((p[:, None] * tf.gather(self.a, self.nonzero_indices, axis=1) * p[:, None])/(1 + p[:, None] * t[None, :])**2, axis=0) + self.d[self.nonzero_indices]/(1 - t)**2)\n",
    "    \n",
    "    @tf.function(autograph=False)\n",
    "    def sqF(self, p):\n",
    "        t = tnp.ones_like(self.d, dtype=\"float64\")\n",
    "#         t = np.ones_like(self.d, dtype=\"float64\")\n",
    "        p = tnp.array(list(p))\n",
    "        x0 = t[self.nonzero_indices] * 0\n",
    "        high_bound = tnp.ones_like(self.nonzero_indices, dtype=\"float64\")\n",
    "        low_bound = high_bound * (-1/tnp.max(p))\n",
    "#         tf.print(high_bound)\n",
    "        def func_to_minimize(t):\n",
    "            return self.f_vectorized(t, p)\n",
    "#         t_solved = scipy.optimize.root(func_to_minimize,\n",
    "#                                x0=x0, \n",
    "#                                method='hybr',  # 'krylov',\n",
    "#                                tol=None,\n",
    "#                                callback=None,\n",
    "#                                options={}).x # bounds(-1/max(p), 1)\n",
    "#         t[self.nonzero_indices] = t_solved\n",
    "        t_solved = tfp.math.find_root_chandrupatla(func_to_minimize, low_bound, high_bound).estimated_root\n",
    "#         tf.print(t_solved)\n",
    "        t = tf.tensor_scatter_nd_update(t, self.nonzero_indices_tf, t_solved)\n",
    "#         A = tf.constant(self.a/(1 + p[:, None]*t[None, :]), dtype=\"float64\") \n",
    "        A = tnp.maximum(self.a/(1 + p[:, None]*t[None, :]), 0.05)\n",
    "        \n",
    "        return tnp.sum(tnp.sum(self.d[None, :] *  A / tnp.sum(p[None, :] * A.transpose(), axis=1) - A, axis=1)**2, axis=0)\n",
    "\n",
    "    sqF.errordef = 0.5\n",
    "    \n",
    "    def fit(self, eps):\n",
    "        minimizer = zfit.minimize.Minuit(tol=eps) \n",
    "        def func(x):\n",
    "            # print(x)\n",
    "            # if not tf.is_tensor(x):\n",
    "            x = list(x)\n",
    "            return self.sqF(x)\n",
    "        func.errordef = 0.5\n",
    "\n",
    "        return np.array(minimizer.minimize(func, self.p).params)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
