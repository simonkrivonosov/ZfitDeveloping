{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/zfit/util/execution.py:70: UserWarning: Not running on Linux. Determining available cpus for thread can failand be overestimated. Workaround (only if too many cpus are used):`zfit.run.set_n_cpu(your_cpu_number)`\n",
      "  warnings.warn(\"Not running on Linux. Determining available cpus for thread can fail\"\n"
     ]
    }
   ],
   "source": [
    "import zfit\n",
    "import math\n",
    "from zfit import z\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "zfit.settings.options['numerical_grad'] = True\n",
    "class HistPDF(zfit.pdf.BasePDF):\n",
    "\n",
    "    def __init__(self, hist_args, hist_bins, obs, name='HistPDF'):\n",
    "        self.rv_hist = scipy.stats.rv_histogram([hist_args, hist_bins])\n",
    "        super().__init__(obs=obs, name=name)\n",
    "\n",
    "    def _unnormalized_pdf(self, x):\n",
    "        x = z.unstack_x(x)\n",
    "        probs =  z.py_function(func=self.rv_hist.pdf, inp=[x], Tout=tf.float64)\n",
    "        probs.set_shape(x.shape)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu2 = zfit.Parameter(\"mu2\", 5., step_size=0)\n",
    "# sigma2 = zfit.Parameter(\"sigma2\", 1., step_size=0)\n",
    "# lambd2 = zfit.Parameter(\"lambda2\", -0.2, step_size=0)\n",
    "# frac2 = zfit.Parameter(\"fraction2\", 0.5, 0, 1)\n",
    "# frac1 = zfit.Parameter(\"fraction1\", 0.5, step_size=0)\n",
    "# create space\n",
    "obs1 = zfit.Space(\"x\", limits=(0, 10))\n",
    "obs2 = zfit.Space(\"x\", limits=(0, 10))\n",
    "\n",
    "# parameters\n",
    "mu1 = zfit.Parameter(\"mu1\", 5., 1, 10, step_size=0)\n",
    "sigma1 = zfit.Parameter(\"sigma1\", 1., 0.1, 10, step_size=0)\n",
    "lambd1 = zfit.Parameter(\"lambda1\", -0.2, -1, -0.01, step_size=0)\n",
    "frac1 = zfit.Parameter(\"fraction1\", 0.5, 0, 1)\n",
    "\n",
    "mu2 = zfit.Parameter(\"mu2\", 5., step_size=0)\n",
    "sigma2 = zfit.Parameter(\"sigma2\", 1., step_size=0)\n",
    "lambd2 = zfit.Parameter(\"lambda2\", -0.2, step_size=0)\n",
    "frac2 = zfit.Parameter(\"fraction2\", 0.5, step_size=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gauss1 = zfit.pdf.Gauss(mu=mu1, sigma=sigma1, obs=obs1)\n",
    "exponential1 = zfit.pdf.Exponential(lambd1, obs=obs1)\n",
    "model1 = zfit.pdf.SumPDF([gauss1, exponential1], fracs=frac1)\n",
    "\n",
    "\n",
    "gauss2 = zfit.pdf.Gauss(mu=mu2, sigma=sigma2, obs=obs2)\n",
    "exponential2 = zfit.pdf.Exponential(lambd2, obs=obs2)\n",
    "model2 = zfit.pdf.SumPDF([gauss2, exponential2], fracs=frac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function BaseModel.sample.<locals>.run_tf at 0x1044b28400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function BaseModel.sample.<locals>.run_tf at 0x1044ba9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function counts_multinomial.<locals>.wrapped_func at 0x1051329c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function BaseModel.sample.<locals>.run_tf at 0x10513a6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function BaseModel.sample.<locals>.run_tf at 0x10513a6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function counts_multinomial.<locals>.wrapped_func at 0x10449ff950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function BaseModel.sample.<locals>.run_tf at 0x105141dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function BaseModel.sample.<locals>.run_tf at 0x105147b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "n_sample = 10000\n",
    "\n",
    "exp_data = exponential2.sample(n=n_sample * (1 - frac1)).numpy()\n",
    "\n",
    "gauss_data = gauss2.sample(n=n_sample * frac1).numpy()\n",
    "\n",
    "data = model1.create_sampler(n_sample, limits=obs1)\n",
    "data.resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = data[:, 0].numpy()\n",
    "exp_data_np = exp_data[:, 0]\n",
    "gauss_data_np = gauss_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hist = np.histogram(data_np, bins=30)\n",
    "exp_data_hist = np.histogram(exp_data_np, bins=30)\n",
    "gauss_data_hist = np.histogram(gauss_data_np, bins=30)\n",
    "sim_hists = []\n",
    "sim_hists.append(exp_data_hist)\n",
    "sim_hists.append(gauss_data_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.1910227239630367,\n",
       " -0.09120326850520033,\n",
       " -0.10931785904766811,\n",
       " -0.10665205976022588,\n",
       " -0.0963624241348762,\n",
       " -0.0894536699858964,\n",
       " -0.0073706162398816805,\n",
       " 0.04608105120379543,\n",
       " 0.12514334679545236,\n",
       " 0.1064613869543524,\n",
       " 0.006047143857805151,\n",
       " 0.00036238515359962586,\n",
       " 0.002123975314090712,\n",
       " -0.05379251641630914,\n",
       " -0.029623096858800047,\n",
       " -0.050071575955320385,\n",
       " -0.008628466840409077,\n",
       " -0.024198223788164136,\n",
       " 0.03507114037467561,\n",
       " 0.16327506024191146,\n",
       " 0.1489122752095554,\n",
       " 0.2382042139660016,\n",
       " 0.22599607727765256,\n",
       " 0.18320414397970947,\n",
       " 0.07820939791374207,\n",
       " -0.10751515825172248,\n",
       " 0.04889621371506556,\n",
       " -0.1928811025335132,\n",
       " -0.061713746924123875,\n",
       " -0.022469695700650355]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FractionFitter(object):\n",
    "\n",
    "    def __init__(self, data_hist, sim_hists, P):\n",
    "        self.data_hist = data_hist\n",
    "        self.P = P\n",
    "        self.sim_hists = [hist for hist in sim_hists]\n",
    "        self.d = self.data_hist[0] # where d[i] amount of events in bin from data\n",
    "        self.N_D = np.sum(self.data_hist[0])#all observable data amount\n",
    "        self.N = [np.sum(h[0]) for h in sim_hists]# amount of simulation data from sources e.g. N[0] from source 0 .. N[j] from source j\n",
    "        self.sources_num = len(P)\n",
    "        self.bins_num = len(data_hist[0])\n",
    "        \n",
    "    def norma(self, v):\n",
    "        return math.sqrt(sum(vi ** 2 for vi in v))\n",
    "    #function to minimize for finding optimat t according to (15) from the paper        \n",
    "    def sq_f(self, t, a, p, i):\n",
    "        return (np.sum((p[:] * a[:, i] / (1 + p[:] * t))) - self.d[i]/(1 - t))**2 \n",
    "    \n",
    "    def f(self, t, a, p, i):\n",
    "        return np.sum((p[:] * a[:, i] / (1 + p[:] * t))) - self.d[i]/(1 - t)\n",
    "    \n",
    "    def der_f(self, t, a, p, i):\n",
    "        return -2 * self.f(t, a, p, i) * (np.sum((p[:] * a[:, i])*(p[:]/(1 + p[:] * t)**2)) + self.d[i]/(1 - t)**2)\n",
    "    \n",
    "    def sqF(self, p, A): # need to find optimal step for p, p_(k+1) = p_k - k * sqF/div_sqF\n",
    "        res = 0\n",
    "        for j in range(self.sources_num):\n",
    "            tmp_res = 0\n",
    "            for i in range(self.bins_num):\n",
    "                tmp_res += ((self.d[i] * A[j][i])/np.sum(p[:] * A[:, i]) - A[j][i])\n",
    "            res += tmp_res**2\n",
    "            \n",
    "        return res\n",
    "                \n",
    "    def div_sqF(self, p, k, A):\n",
    "        res = 0\n",
    "        for j in range(self.sources_num):\n",
    "            sum1 = 0\n",
    "            sum2 = 0\n",
    "            for i in range(self.bins_num):\n",
    "                sum1 -= (self.d[i] * A[j][i] * A[k][i])/(np.sum(p[:] * A[:, i]))**2\n",
    "                sum2 += ((self.d[i] * A[j][i])/np.sum(p[:] * A[:, i]) - A[j][i])\n",
    "            res += sum1*sum2\n",
    "        return res\n",
    "            \n",
    "\n",
    "    def fit(self, eps):\n",
    "        # let assume initial set of p_j:\n",
    "        p = []\n",
    "        p_new = []\n",
    "        for i in range(self.sources_num):\n",
    "            p.append(self.N_D * self.P[i]/self.N[i])\n",
    "        p_new = p.copy()\n",
    "\n",
    "        a = np.array([[0.0] * self.bins_num for i in range(self.sources_num)])#a[j][i] amount of observations in i bin from j source\n",
    "        for j in range(self.sources_num):\n",
    "            for i in range(self.bins_num):\n",
    "                a[j][i] = self.sim_hists[j][0][i]\n",
    "        while(True): \n",
    "#             t0 = [] # initial values for t\n",
    "#             for i in range(self.bins_num):\n",
    "#                 t0.append(1 - self.d[i]/np.sum(p[:]*a[:, i]))\n",
    "            t = []# t[i] = 1 - d[i]/f[i]\n",
    "            # t calculating ...\n",
    "            for i in range(self.bins_num):\n",
    "                if(self.d[i] == 1):\n",
    "                    t.append(1)\n",
    "                    continue\n",
    "#                 t.append(minimize(self.f, 0, args=(a, p, i), method='nelder-mead', bounds=bnds\n",
    "#                                   options={'xtol': 1e-3, 'disp': False}).x[0])\n",
    "                t.append(minimize(self.sq_f, 0, args=(a, p, i), method='TNC', jac=self.der_f, bounds=[(-1/max(p), 1)],\n",
    "                                  ).x[0]) # L-BFGS-B, TNC, SLSQP, trust-constr\n",
    "            print(\"-1/max(p)= \", -1/max(p))\n",
    "            print(t)\n",
    "            A = np.array([[0.0] * self.bins_num for i in range(self.sources_num)])#A[j][i] fitted amount of observations in i bin from j source\n",
    "            for j in range(self.sources_num):\n",
    "                for i in range(self.bins_num):\n",
    "                    A[j][i] = a[j][i]/(1 + p[j]*t[i])\n",
    "                    if(A[j][i] == 0.0):\n",
    "                        A[j][i] = 0.1\n",
    "                    \n",
    "            print(\"p=\", p)\n",
    "            #bounds on sum of p = 1 and p > 0\n",
    "            #\n",
    "            for i in range(len(p)):\n",
    "                p_new[i] = p[i] - self.sqF(p, A)/self.div_sqF(p, i, A)\n",
    "                \n",
    "            print(np.abs(self.norma(p_new) - self.norma(p)))\n",
    "            if np.abs(self.norma(p_new) - self.norma(p)) < eps:\n",
    "                return p\n",
    "            \n",
    "            p = p_new.copy()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "[-0.1910227239630367, -0.09120326850520033, -0.10931785904766811, -0.10665205976022588, -0.0963624241348762, -0.0894536699858964, -0.0073706162398816805, 0.04608105120379543, 0.12514334679545236, 0.1064613869543524, 0.006047143857805151, 0.00036238515359962586, 0.002123975314090712, -0.05379251641630914, -0.029623096858800047, -0.050071575955320385, -0.008628466840409077, -0.024198223788164136, 0.03507114037467561, 0.16327506024191146, 0.1489122752095554, 0.2382042139660016, 0.22599607727765256, 0.18320414397970947, 0.07820939791374207, -0.10751515825172248, 0.04889621371506556, -0.1928811025335132, -0.061713746924123875, -0.022469695700650355]        \n",
    "#[-0.19102295744353537, -0.09120326835219963, -0.10931785880809863, -0.10665205920955251, -0.09636174689216719, -0.08945375038584087, -0.007370615890315419, 0.046081050707275854, 0.12514334288495768, 0.10646127812101377, 0.006047139112798052, 0.00036241956853135584, 0.0021239780321641666, 0.0, 0.0, 0.0, -0.008628466669366227, -0.02419822333965582, 0.03507114035165261, 0.0, 0.14891217892738554, 0.23820417806086028, 0.22599607223906812, 0.1832040602477388, 0.0782094006230153, -0.10751748996740138, 0.048896207321515096, -0.19288019044692606, -0.06171240267850805, -0.022472437888663484]        \n",
    "#[0.0, 0.0, 0.0, -2.2298861614628904e-07, 0.0, 3.1645219631861396e-07, 1.12047574665657e-07, 0.0, -2.6247998010836906e-07, -2.2911108283838328e-07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = FractionFitter(data_hist=data_hist, sim_hists=sim_hists, P=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1/max(p)=  -0.8333333333333334\n",
      "[-0.1910227239630367, -0.09120326850520033, -0.10931785904766811, -0.10665205976022588, -0.0963624241348762, -0.0894536699858964, -0.0073706162398816805, 0.04608105120379543, 0.12514334679545236, 0.1064613869543524, 0.006047143857805151, 0.00036238515359962586, 0.002123975314090712, -0.05379251641630914, -0.029623096858800047, -0.050071575955320385, -0.008628466840409077, -0.024198223788164136, 0.03507114037467561, 0.16327506024191146, 0.1489122752095554, 0.2382042139660016, 0.22599607727765256, 0.18320414397970947, 0.07820939791374207, -0.10751515825172248, 0.04889621371506556, -0.1928811025335132, -0.061713746924123875, -0.022469695700650355]\n",
      "p= [0.8, 1.2]\n",
      "0.5802567268922386\n",
      "-1/max(p)=  -1.173133753886307\n",
      "[-0.15275502758550805, -0.05819211595938108, -0.08071191835546714, -0.0737867875530252, -0.08048453096628498, -0.13897926947798223, -0.10967954042012046, -0.13632586646172504, -0.12474321938830873, -0.27189583311404564, -0.4942226438122561, -0.5566916802707916, -0.6528885919945582, -0.737776210043364, -0.7535708910954547, -0.8228283987458799, -0.7663748533798661, -0.7398012931224941, -0.6658139562663377, -0.5147453225956728, -0.4385021730188713, -0.2787466655122164, -0.16896389475249135, -0.04087567925316835, -0.11317508331951259, -0.21386558056772037, 0.018535218731789302, -0.2124224830735458, -0.05262856926191718, -0.01266846727556857]\n",
      "p= [0.852417720219236, 0.12792808122393606]\n",
      "0.3942079943135929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1/max(p)=  -0.8540692657120563\n",
      "[0.01685025465031445, 0.09787225164798352, 0.07945646039920863, 0.08466519155098907, 0.08169297481795754, 0.04295166201950722, 0.07899374867607802, 0.07465831375490432, 0.10435352402324823, 0.011191996788397718, -0.16087856973794784, -0.20235899018303566, -0.2627058135474979, 0.0, 0.0, 0.0, 0.0, -0.3324537702755438, -0.2546595068228158, -0.09716847621670188, -0.06422190414962778, 0.06519103649029197, 0.1163603791673419, 0.17206478794167573, 0.09769047139441889, -0.01123128716613156, 0.17467898329601417, -0.02542981445438673, 0.10654672603410845, 0.14044621140064528]\n",
      "p= [1.1708652215301039, 0.4550188653973212]\n",
      "0.6373532469699208\n",
      "-1/max(p)=  -0.5727366568743251\n",
      "[0.16613480529926267, 0.2349562117897572, 0.21956249391395963, 0.22378191998999095, 0.22203673674662203, 0.19235944443761827, 0.2258894765726868, 0.22712367994632504, 0.2571139029129046, 0.18719407967368243, 0.04946150422581219, 0.0189011806477615, -0.02334924747876513, -0.09180706028852387, -0.086634315992766, -0.13195754242927704, -0.08074218540109168, -0.07715346295261521, -0.011207013332522497, 0.12178117603674628, 0.14103836209014178, 2.7755575615628914e-17, 2.7755575615628914e-17, 2.7755575615628914e-17, 0.24736766641021607, 0.1492798206377432, 0.3031691200405144, 0.13281351707311362, 0.2434131292550761, 0.2720987271659583]\n",
      "p= [1.746003137737749, 0.7327414698983367]\n",
      "0.44111214415510314\n",
      "-1/max(p)=  -0.7182335931674865\n",
      "[0.08878900083816889, 0.16379089582098932, 0.14652371157904343, 0.1515264127592632, 0.14808539206618496, 0.10936911416638798, 0.14007441351971958, 0.13155305984490226, 0.15444902555793774, 0.059796205729108154, -0.10599614609843969, -0.1482484148241633, -0.2115320849710406, -0.2869572741402851, -0.2909605626477052, -0.34784996673687074, -0.2932381120450773, -0.2795102055483458, -0.20935099370891785, -0.06636730349241007, -0.027211628158524848, 0.09671623798649973, 0.15425240356471648, 0.2184027268858849, 0.15217959540914092, 0.056647493941196336, 0.2322014505720177, 0.04739645931720028, 0.17085259567301708, 0.20232450569674817]\n",
      "p= [1.3923046896064744, 0.4135103705046288]\n",
      "0.337378709530725\n",
      "-1/max(p)=  -0.5906171174380535\n",
      "[0.1565547894956364, 0.22606849133537904, 0.210280178312355, 0.21473941847190017, 0.2122261015973884, 0.17913971494553482, 0.2102021392955165, 0.20671899436074534, 0.23243184872334988, 0.15294656691375963, 0.005692033474965302, -0.029681042845885963, -0.08103903585962707, -0.1515036231869693, -0.15093425840205382, -0.20128107090122, -0.14911141254561716, -0.14065582171480473, -0.07386422274604854, 0.06130954287275381, 0.08913339298170374, 0.19991614534275418, 0.24330367142510584, 0.0, 0.2265143397690648, 0.13279061261094036, 0.29210738952095255, 0.12040118991186595, 0.23356229129133732, 0.26264172719651213]\n",
      "p= [1.693144290056721, 0.5801864773613691]\n",
      "0.5660796544253552\n",
      "-1/max(p)=  -0.8854050107493909\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.24016787379203364, -0.13533201691591687, -0.01987147004252711, -0.005237210383364041, -0.08748629861919291, -0.08377309825023313, -0.06802662078580157, -0.12085206229060677, -0.0918431184303039, -0.10695323016625974, -0.06704337062480438, -0.08734334686057849, -0.028854625425139127, 0.10207414238872392, 0.07641837063466846, 0.16370789078691386, 0.13053664297593723, 0.0377671075968747, -0.09516269780510989, 0.0, -0.23455023420067478, 0.0, 0.0, 0.0]\n",
      "p= [0.47102694419603, 1.1294266328509006]\n",
      "0.8800936791255254\n",
      "-1/max(p)=  -0.5036300348996486\n",
      "[-0.2842261423400943, -0.17485927894865028, -0.18533878942867904, -0.1900170345903277, -0.15397191529175058, -0.08402640295937047, 0.021058076898426537, 0.10199596117419135, 0.1924309466323403, 0.20228574788524306, 0.13554725900735365, 0.1380698410363896, 0.15001136103372864, 0.10764598072865347, 0.13061731042637556, 0.1183072692565579, 0.15026804865593235, 0.13425480969437156, 0.1810384391403152, 0.2855639097807944, 0.26560373740650983, 0.3355043618925053, 0.3100813119395048, 0.23866965523676387, 0.1337497010097402, -0.06445600591383494, 0.029605836162523963, -0.19839078986057346, -0.11245896863169236, -0.07538454762951058]\n",
      "p= [0.6953072607732639, 1.9855845178083078]\n",
      "0.5542045335891723\n",
      "-1/max(p)=  -0.653443490084313\n",
      "[-0.6501381816260137, -0.6463674657289389, -0.6386685169146231, -0.6455012650367333, -0.6188081081911674, -0.5235103912726209, -0.43067639117570183, -0.30684143508634026, -0.18286953870491884, -0.08413904336920042, -0.08612102927326121, -0.06305627039207087, -0.02169750188462341, -0.053319253065460454, -0.022103904765033794, -0.022544907017704452, 0.004326958327035585, -0.020706030059782776, 0.020153539120715963, 0.11907533671961382, 0.07057448732138895, 0.11803784954865933, 0.030029165853587253, -0.16999771737249347, -0.2784564086112759, -0.4583296108027736, -0.5277220763445469, -0.5766886633075416, -0.6071342090697618, -0.6071490067033216]\n",
      "p= [-0.24347378473996073, 1.5303542160485388]\n",
      "0.21968841552971452\n",
      "-1/max(p)=  -0.5652378134869649\n",
      "[2.7755575615628914e-17, 2.7755575615628914e-17, 2.7755575615628914e-17, 2.7755575615628914e-17, 2.7755575615628914e-17, -0.4132546642914451, -0.30824737657598045, -0.1800655388858346, -0.05508469001744287, 0.02394757145446233, 0.004187909658949468, 0.021695827665629636, 0.05464461113410771, 0.020469798486112856, 0.0489546912557082, 0.04523845421612763, 0.07306614185550775, 0.050952932329967615, 0.09295558537598637, 0.19280003263626763, 0.15343485077447017, 0.20864188685624968, 0.13965377125060396, -0.03230461531802675, -0.14873540278420655, -0.34566194883275037, -0.40899226419213663, 2.7755575615628914e-17, 2.7755575615628914e-17, 2.7755575615628914e-17]\n",
      "p= [-0.020832476051335064, 1.7691668464835666]\n",
      "0.03542065177092457\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "p = fitter.fit(1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.020832476051335064, 1.7691668464835666]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "for j in range(len(p)):\n",
    "    P.append(p[j] * fitter.N[j]/fitter.N_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.010416238025667532, 0.8845834232417834]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [100.8729970684941, 73.80758908842088]\n",
    "A = np.array([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2 ,2, 2, 1 ,1 ,1 ,1,1,1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "  0, 1, 1, 0, 0, 0, 0, 0 ,0, 0, 0 ,0 ,0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0 ,0, 0, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0,\n",
    "  0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1 ,1, 1, 1, 1, 1],\n",
    " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1,\n",
    "  2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1 ,1,\n",
    "  1, 1, 1, 1, 1, 1, 1 ,0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3137230728196598\n"
     ]
    }
   ],
   "source": [
    "print(np.sum((P[:] * A[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300.57142857142856\n"
     ]
    }
   ],
   "source": [
    "print(fitter.d[0]/3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
